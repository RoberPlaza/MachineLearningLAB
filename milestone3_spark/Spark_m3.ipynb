{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We read merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "data_merged = sqlCtx.read.load('file:///home/lajotadeladerrota/Escritorio/Universidad/4Curso/MachineLearning/LAB/MachineLearningLAB/milestone3_spark/data/data_merged.csv',\n",
    "                   format='com.databricks.spark.csv', header='true',\n",
    "                    inferSchema='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GyroscopeStat_x_MEAN',\n",
       " 'GyroscopeStat_z_MEAN',\n",
       " 'GyroscopeStat_COV_z_x',\n",
       " 'GyroscopeStat_COV_z_y',\n",
       " 'MagneticField_x_MEAN',\n",
       " 'MagneticField_z_MEAN',\n",
       " 'MagneticField_COV_z_x',\n",
       " 'MagneticField_COV_z_y',\n",
       " 'Pressure_MEAN',\n",
       " 'LinearAcceleration_COV_z_x',\n",
       " 'LinearAcceleration_COV_z_y',\n",
       " 'LinearAcceleration_x_MEAN',\n",
       " 'LinearAcceleration_z_MEAN',\n",
       " 'attack']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrintSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GyroscopeStat_x_MEAN: double (nullable = true)\n",
      " |-- GyroscopeStat_z_MEAN: double (nullable = true)\n",
      " |-- GyroscopeStat_COV_z_x: double (nullable = true)\n",
      " |-- GyroscopeStat_COV_z_y: double (nullable = true)\n",
      " |-- MagneticField_x_MEAN: double (nullable = true)\n",
      " |-- MagneticField_z_MEAN: double (nullable = true)\n",
      " |-- MagneticField_COV_z_x: double (nullable = true)\n",
      " |-- MagneticField_COV_z_y: double (nullable = true)\n",
      " |-- Pressure_MEAN: double (nullable = true)\n",
      " |-- LinearAcceleration_COV_z_x: double (nullable = true)\n",
      " |-- LinearAcceleration_COV_z_y: double (nullable = true)\n",
      " |-- LinearAcceleration_x_MEAN: double (nullable = true)\n",
      " |-- LinearAcceleration_z_MEAN: double (nullable = true)\n",
      " |-- attack: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_merged.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We aggregate features to make predictions into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = ['GyroscopeStat_x_MEAN',\n",
    " 'GyroscopeStat_z_MEAN',\n",
    " 'GyroscopeStat_COV_z_x',\n",
    " 'GyroscopeStat_COV_z_y',\n",
    " 'MagneticField_x_MEAN',\n",
    " 'MagneticField_z_MEAN',\n",
    " 'MagneticField_COV_z_x',\n",
    " 'MagneticField_COV_z_y',\n",
    " 'Pressure_MEAN',\n",
    " 'LinearAcceleration_COV_z_x',\n",
    " 'LinearAcceleration_COV_z_y',\n",
    " 'LinearAcceleration_z_MEAN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols = features, outputCol=\"features\")\n",
    "assembled = assembler.transform(data_merged)\n",
    "\n",
    "(trainingData, testData) = assembled.randomSplit([0.67,0.33], seed=13234)\n",
    "trainingData.count(), testData.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "d_tree = DecisionTreeClassifier(labelCol = \"attack\", featuresCol = \"features\", maxDepth=1,\n",
    "                                minInstancesPerNode = 20, impurity = \"gini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[d_tree])\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction|attack|\n",
      "+----------+------+\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       1.0|   1.0|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\",\"attack\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\",\"attack\").write.save(path=\"file:///home/lajotadeladerrota/Escritorio/Universidad/4Curso/MachineLearning/LAB/MachineLearningLAB/milestone3_spark/data/predictions_test\",\n",
    "                                                      format=\"com.databricks.spark.csv\",header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sqlContext.read.load('file:///home/lajotadeladerrota/Escritorio/Universidad/4Curso/MachineLearning/LAB/MachineLearningLAB/milestone3_spark/data/predictions',\n",
    "                                                      format=\"com.databricks.spark.csv\",header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction|attack|\n",
      "+----------+------+\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       1.0|   1.0|\n",
      "|       1.0|   1.0|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"attack\",\n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
